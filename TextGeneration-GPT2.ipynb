{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"yIJyTR6UibXQ"},"source":["# Introduction\n","In this notebook, we'll see how to fine-tune Transformers model on a language modeling task to generate arabic text. We will cover one of language modeling tasks which are:\n","\n","\n","- Causal language modeling: the model has to predict the next token in the sentence (so the labels are the same as the inputs shifted to the right). To make sure the model does not cheat, its attention computations are masked so that tokens cannot attend to tokens to their right, as this would result in label leakage.\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"xQEQzVE5iq8I"},"source":["Install the important library"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HHN0i2UAnW7q"},"outputs":[],"source":["!pip install datasets \n","!pip install --upgrade accelerate\n","!pip uninstall -y transformers accelerate\n","!pip install transformers accelerate\n","! pip install datasets transformers[sentencepiece]"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"zIlJDlQNjq5l"},"source":["import the important library"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sFtbEBhG6cif"},"outputs":[],"source":["import transformers\n","from datasets import load_dataset\n","from sklearn.model_selection import train_test_split\n","from transformers import AutoTokenizer\n","from transformers import AutoModelForCausalLM\n","from transformers import Trainer, TrainingArguments\n","import math\n","from transformers import pipeline"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"kID3xLVjjxDv"},"source":["# Preparing the dataset"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"s_6VTROZj0tj"},"source":["load a corpus and split it to training and validation dataset, you can find the corpus in the following link : https://sourceforge.net/projects/ksucca-corpus/files/"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":[" ##### Split the corpus to training and testing set"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gIixgbYYgj22"},"outputs":[],"source":["# Load the text document as a single string\n","with open('/content/sample_data/aa1.txt', 'r') as f:\n","    text = f.read()\n","\n","# Split the text into an array of strings using the newline character as the delimiter\n","lines = text.split('\\n')\n","\n","# Split the lines array into training and test datasets\n","train_lines, test_lines = train_test_split(lines, test_size=0.2, random_state=42)\n","\n","# Join the training and test datasets into strings\n","train_text = '\\n'.join(train_lines)\n","test_text = '\\n'.join(test_lines)\n","\n","# Write the training and test datasets to separate text files\n","with open('/content/sample_data/train.txt', 'w') as f:\n","    f.write(train_text)\n","\n","with open('/content/sample_data/test.txt', 'w') as f:\n","    f.write(test_text)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"aRtmmOr6kARQ"},"source":["load the dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Sd55vSgi6s6R"},"outputs":[],"source":["datasets = load_dataset(\"text\", data_files={\"train\": '/content/sample_data/train.txt', \"validation\": '/content/sample_data/test.txt'})"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"0JNvlXIHkJ_Q"},"source":["# Causal Language modeling\n","\n","Causal language modeling is a type of natural language processing task that involves predicting the most likely next word or sequence of words given a context. The \"causal\" part of the term refers to the fact that the model generates text in a forward direction, i.e., it predicts the next word based on the previous words in the sequence."]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"e5b255aqkNII"},"source":["identify the model (GPT2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kowwDKPw7Lx4"},"outputs":[],"source":["model_checkpoint = \"aubmindlab/aragpt2-base\""]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"HvH78KGLkVOB"},"source":["load the tokenizer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LfQiPdVO8zGp"},"outputs":[],"source":["#tokenizer will use the fast tokenization algorithm, which is based on byte-level byte-pair encoding (BPE) tells the tokenizer to use the fast tokenization algorithm, which is faster and supports additional features.\n","tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"BSR9za3Jke9B"},"source":["define the tokenization function "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xshcx1yt8DMZ"},"outputs":[],"source":["def tokenize_function(examples):\n","    return tokenizer(examples[\"text\"])"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"ZPuxI0ZOknNY"},"source":["tokenize the dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uMetu1Pv7fku"},"outputs":[],"source":["#batched=True: This parameter tells the map() method to apply the tokenize_function to examples in batches, rather than one at a time \n","#divide the input dataset into smaller batches, each containing a fixed number of samples.(1000 default)\n","#num_proc=4: This parameter tells the map() method to use 4 processes to parallelize the tokenization.\n","tokenized_datasets = datasets.map(tokenize_function, batched=True, num_proc=4, remove_columns=[\"text\"])"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Q2HK_CrKk5KA"},"source":["preprocessing function that will group the texts\n","\n","- The group_texts function takes a list of examples, where each example is a dictionary that contains the input text and label for a specific task. The function concatenates all the input texts together and splits the concatenated text into chunks of a maximum length of 128 tokens. The labels are also split in the same way. The function returns a dictionary that contains the split input texts and labels ( in a language modeling task, the input text is a sequence of words, and the label is the next word in the sequence.).\n","\n","- By splitting the labels in the same way as the input texts, the function ensures that the labels correspond to the correct input text chunks. This allows the language model to learn to predict the next token in the sequence or classify the input text based on the corresponding label for each input text chunk.\n","\n","- Note that by default, the map method will send a batch of 512 examples to be treated by the preprocessing function. So here, we will drop the remainder to make the concatenated tokenized texts a multiple of block_size every 512 examples."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wjuJ6Oaw_ExV"},"outputs":[],"source":["def group_texts(examples):\n","    # Concatenate all texts.\n","    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n","    total_length = len(concatenated_examples[list(examples.keys())[0]])\n","    # We drop the small remainder\n","    total_length = (total_length // 128) * 128\n","    # Split by chunks of max_len.\n","    result = {\n","        k: [t[i : i + 128] for i in range(0, total_length, 128)]\n","        for k, t in concatenated_examples.items()\n","    }\n","    result[\"labels\"] = result[\"input_ids\"].copy()\n","    return result"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17,"referenced_widgets":["3655085be4cf4848a2316f7ea6c36400","b5139fb09d924e3da3d61470520abae0","ceee153c7e5b45bb9ff909a0d46d2b90","cd797ff396f849bc9b1b773187c94cd1","e4e4f2a2f79b414f88176f86bff6e1c2","7e73b1b5d3b84a9e8d39bcadba107676","40762ce34aaf4d0d868fce4d461a83d4","b11d8f2030384786b0a8336ebf76b021","3878e540b2f24766a26c723606d1aa85","8cfe08ded2e74bb29d586837ff077571","0395bb86632d4f3aba960d3d991256a4","148c2d0cd0544d80997fa0e93eaeb42f","f36c1582509143ada31d2ddc90ba9ffa","42d9966474224d71a032e45b54d38b15","2ac19361c13b4622a3f589d98e9198fd","0b3221e045f34b3581f6588ec8494ee0","34579aabfcfc4c309c46682da2a5523c","1ab1417d9d9f477e8cac17768848ed6a","d42715e9cfc746f28d16e010666e23e4","24845bfdf8064efa826feb99804244ea","2c791be150fe409cb27223430ab77767","ea1e356ac4d6416784725cc1dd3b0e15"]},"executionInfo":{"elapsed":1784,"status":"ok","timestamp":1686021271973,"user":{"displayName":"عبدالرحمن العنزي","userId":"13678026248837156341"},"user_tz":-180},"id":"DiIEVVPj_RZQ","outputId":"20499a39-7594-46df-9e85-6d451f97a588"},"outputs":[],"source":["lm_datasets = tokenized_datasets.map(\n","    group_texts,\n","    batched=True,\n","    batch_size=512,\n","    num_proc=4,\n",")"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"A1baJNZJluBY"},"source":["load the model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mKD7G2yn_ljf"},"outputs":[],"source":["model = AutoModelForCausalLM.from_pretrained(model_checkpoint)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"B6HxUzPtm4j9"},"source":["identify the training argument"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l6oBInG9_psl"},"outputs":[],"source":["model_name = model_checkpoint.split(\"/\")[-1]\n","training_args = TrainingArguments(\n","    f\"{model_name}-finetuned-wikitext2\",\n","    evaluation_strategy = \"epoch\",\n","    learning_rate=2e-5,\n","    weight_decay=0.01,\n","    num_train_epochs=10,\n",")"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"nFWMfZBBrvcx"},"source":["train the model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zRtk5QAPBLAT"},"outputs":[],"source":["trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=lm_datasets[\"train\"],\n","    eval_dataset=lm_datasets[\"validation\"],\n","\n",")\n","trainer.train()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"psAAtEJ4wFY7"},"source":[" evaluate our model and get its perplexity "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"elapsed":2675,"status":"ok","timestamp":1686021719000,"user":{"displayName":"عبدالرحمن العنزي","userId":"13678026248837156341"},"user_tz":-180},"id":"KkbBKaF6G0pH","outputId":"c702ed0a-bde7-40b5-fe69-726ad5db4b2c"},"outputs":[{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [21/21 00:02]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Perplexity: 38.32\n"]}],"source":["eval_results = trainer.evaluate()\n","print(f\"Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"gRFPD-KMwJnO"},"source":["save the model and tokenizer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bcxZcAtzbGJn"},"outputs":[],"source":["model.save_pretrained(\"/content/sample_data/sa\")\n","tokenizer.save_pretrained(\"/content/sample_data/sa\")"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"d8-A7nLZwN90"},"source":["load the model and tokenizer "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qaJJXw6ct03s"},"outputs":[],"source":["# Load the model and tokenizer\n","model = AutoModelForCausalLM.from_pretrained('/content/sample_data/sa')\n","tokenizer = AutoTokenizer.from_pretrained('/content/sample_data/sa')"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"6JvoHGerwSDN"},"source":["create pipeline to generate text"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NIPb7W83wV_t"},"outputs":[],"source":["#specifies the maximum length of the generated text (in terms of number of tokens) that the pipeline can output.\n","pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, config={\"max_length\": 800})"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Z5sgitBKwc10"},"source":["# Testing Sample"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6165,"status":"ok","timestamp":1686022016610,"user":{"displayName":"عبدالرحمن العنزي","userId":"13678026248837156341"},"user_tz":-180},"id":"djaNUgKXt056","outputId":"bfcd7f32-ce40-44be-e7a5-cd1c972640ae"},"outputs":[{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["جعل الله الكعبة البيت الحرام قياماوالذين آمنوا وعملوا الصالحات وأقاموا الصلاة وآتوا الزكاة واجتنبوا ما حرم الله ورسوله وأولئك هم الفاسقونفبأي آلاء ربكما تكذبانيا أيها الذين آمنوا اتقوا الله واعلموا أن الله غفور رحيم\n"]}],"source":["print(pipe('جعل الله الكعبة البيت الحرام قياما')[0]['generated_text'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8232,"status":"ok","timestamp":1686022113427,"user":{"displayName":"عبدالرحمن العنزي","userId":"13678026248837156341"},"user_tz":-180},"id":"YqNnPjdevJhg","outputId":"6213e110-c356-4078-89dc-ad23fb72528c"},"outputs":[{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["قال قد وقع عليكم من ربكم رجس وغضب يحيق بكم إن كنتم صادقينولقد أرسلنا نوحا إلى قومه فقال يا قوم اعبدوا الله ولا تتبعوا أهواءهم وأطيعوا ما أنزل إليكم من التوراة والإنجيل ولو كرهتم أن تقولوا\n"]}],"source":["print(pipe(\"قال قد وقع عليكم من ربكم رجس وغضب \")[0]['generated_text'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8936,"status":"ok","timestamp":1686022299933,"user":{"displayName":"عبدالرحمن العنزي","userId":"13678026248837156341"},"user_tz":-180},"id":"HCNGLWrjwjwk","outputId":"e0da033b-758a-408c-c160-032dc771511a"},"outputs":[{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["والذين آمنوا وعملوا الصالحات وآمنوا بما نزل على قلوبهم من ربهم فأولئك هم الفائزونقالوا يا موسى ادع لنا ربك أن لا يهدي القوم الظالمينوقال رب إني أخاف عليكم عذاب يوم عظيمفإذا جاءتك رسلنا قالوا آمنا بالله واليوم\n"]}],"source":["print(pipe(\"والذين آمنوا وعملوا الصالحات وآمنوا بما نزل على\")[0]['generated_text'])"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMGIj/edCUN2c/k++fmdVJ+","gpuType":"T4","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0395bb86632d4f3aba960d3d991256a4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0b3221e045f34b3581f6588ec8494ee0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"148c2d0cd0544d80997fa0e93eaeb42f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f36c1582509143ada31d2ddc90ba9ffa","IPY_MODEL_42d9966474224d71a032e45b54d38b15","IPY_MODEL_2ac19361c13b4622a3f589d98e9198fd"],"layout":"IPY_MODEL_0b3221e045f34b3581f6588ec8494ee0"}},"1ab1417d9d9f477e8cac17768848ed6a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"24845bfdf8064efa826feb99804244ea":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2ac19361c13b4622a3f589d98e9198fd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2c791be150fe409cb27223430ab77767","placeholder":"​","style":"IPY_MODEL_ea1e356ac4d6416784725cc1dd3b0e15","value":" 313/1254 [00:00&lt;00:00, 1026.29 examples/s]"}},"2c791be150fe409cb27223430ab77767":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"34579aabfcfc4c309c46682da2a5523c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3655085be4cf4848a2316f7ea6c36400":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b5139fb09d924e3da3d61470520abae0","IPY_MODEL_ceee153c7e5b45bb9ff909a0d46d2b90","IPY_MODEL_cd797ff396f849bc9b1b773187c94cd1"],"layout":"IPY_MODEL_e4e4f2a2f79b414f88176f86bff6e1c2"}},"3878e540b2f24766a26c723606d1aa85":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"40762ce34aaf4d0d868fce4d461a83d4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"42d9966474224d71a032e45b54d38b15":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_d42715e9cfc746f28d16e010666e23e4","max":1254,"min":0,"orientation":"horizontal","style":"IPY_MODEL_24845bfdf8064efa826feb99804244ea","value":1254}},"7e73b1b5d3b84a9e8d39bcadba107676":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8cfe08ded2e74bb29d586837ff077571":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b11d8f2030384786b0a8336ebf76b021":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b5139fb09d924e3da3d61470520abae0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7e73b1b5d3b84a9e8d39bcadba107676","placeholder":"​","style":"IPY_MODEL_40762ce34aaf4d0d868fce4d461a83d4","value":"Map (num_proc=4):  81%"}},"cd797ff396f849bc9b1b773187c94cd1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8cfe08ded2e74bb29d586837ff077571","placeholder":"​","style":"IPY_MODEL_0395bb86632d4f3aba960d3d991256a4","value":" 4042/5012 [00:00&lt;00:00, 8276.46 examples/s]"}},"ceee153c7e5b45bb9ff909a0d46d2b90":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_b11d8f2030384786b0a8336ebf76b021","max":5012,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3878e540b2f24766a26c723606d1aa85","value":5012}},"d42715e9cfc746f28d16e010666e23e4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e4e4f2a2f79b414f88176f86bff6e1c2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"ea1e356ac4d6416784725cc1dd3b0e15":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f36c1582509143ada31d2ddc90ba9ffa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_34579aabfcfc4c309c46682da2a5523c","placeholder":"​","style":"IPY_MODEL_1ab1417d9d9f477e8cac17768848ed6a","value":"Map (num_proc=4):  25%"}}}}},"nbformat":4,"nbformat_minor":0}
